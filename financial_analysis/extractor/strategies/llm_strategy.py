"""
LLMæå–ç­–ç•¥ - åŒ…å«DeepSeekå®¢æˆ·ç«¯
LLM Extraction Strategy with DeepSeek Client
"""

import os
import json
import requests
import hashlib
from pathlib import Path
from typing import Any, Optional, Dict
from .base_strategy import BaseStrategy, ExtractionResult

# å°è¯•åŠ è½½ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    # æ‰‹åŠ¨ä».envæ–‡ä»¶åŠ è½½
    env_file = Path(__file__).parent.parent.parent.parent / '.env'
    if env_file.exists():
        with open(env_file, 'r') as f:
            for line in f:
                if line.strip() and not line.startswith('#'):
                    if '=' in line:
                        key, value = line.strip().split('=', 1)
                        os.environ[key] = value


class DeepSeekClient:
    """DeepSeek API å®¢æˆ·ç«¯"""
    
    def __init__(self, api_key: Optional[str] = None):
        """åˆå§‹åŒ–å®¢æˆ·ç«¯"""
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ°DeepSeek APIå¯†é’¥")
        
        self.base_url = "https://api.deepseek.com/v1"
        self.headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        # ç¼“å­˜ç›®å½•
        self.cache_dir = Path("output/llm_cache")
        self.cache_dir.mkdir(parents=True, exist_ok=True)
    
    def _get_cache_key(self, content: str, prompt: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        combined = f"{content[:100]}_{prompt[:50]}"
        return hashlib.md5(combined.encode()).hexdigest()
    
    def _check_cache(self, cache_key: str) -> Optional[Dict]:
        """æ£€æŸ¥ç¼“å­˜"""
        cache_file = self.cache_dir / f"{cache_key}.json"
        if cache_file.exists():
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None
    
    def _save_cache(self, cache_key: str, result: Dict):
        """ä¿å­˜ç¼“å­˜"""
        cache_file = self.cache_dir / f"{cache_key}.json"
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
    
    def extract_financial_data(self, text: str, company_name: str = "", year: str = "") -> Dict:
        """ä½¿ç”¨LLMæå–è´¢åŠ¡æ•°æ®"""
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è´¢åŠ¡æ•°æ®æå–åŠ©æ‰‹ã€‚è¯·ä»è´¢åŠ¡æŠ¥è¡¨æ–‡æœ¬ä¸­å‡†ç¡®æå–ä»¥ä¸‹æ•°æ®ï¼š

1. æ€»èµ„äº§ (Total Assets / Ativo Total / æ€»èµ„äº§) - èµ„äº§è´Ÿå€ºè¡¨ä¸­çš„èµ„äº§æ€»è®¡
2. æ€»è´Ÿå€º (Total Liabilities / Passivo Total / æ€»è´Ÿå€º) - èµ„äº§è´Ÿå€ºè¡¨ä¸­çš„è´Ÿå€ºæ€»è®¡
3. è¥ä¸šæ”¶å…¥ (Revenue / Receita / è¥ä¸šæ”¶å…¥) - æŸç›Šè¡¨ä¸­çš„æ€»æ”¶å…¥æˆ–è¥ä¸šæ”¶å…¥
4. å‡€åˆ©æ¶¦ (Net Profit/Loss / Lucro LÃ­quido / å‡€åˆ©æ¶¦) - æŸç›Šè¡¨ä¸­çš„å‡€åˆ©æ¶¦æˆ–å‡€äºæŸ

æ³¨æ„äº‹é¡¹ï¼š
- è¯·æå–æœ€æ–°æœŸé—´çš„æ•°æ®ï¼ˆå¦‚æœ‰å¤šä¸ªæœŸé—´ï¼‰
- æ•°å­—åº”è¯¥æ˜¯åŸå§‹å€¼ï¼Œä¸è¦è¿›è¡Œå•ä½è½¬æ¢
- å¦‚æœæ˜¯è´Ÿæ•°ï¼ˆäºæŸï¼‰ï¼Œè¯·ä¿ç•™è´Ÿå·
- å¦‚æœæ–‡æœ¬ä¸­æœ‰æ˜ç¡®çš„TOTAL ASSETSã€TOTAL LIABILITIESç­‰æ ‡ç­¾ï¼Œä¼˜å…ˆä½¿ç”¨è¿™äº›æ•°æ®
- å¦‚æœå‘ç°è¡¨æ ¼æ•°æ®ï¼Œè¯·æå–è¡¨æ ¼ä¸­çš„ç›¸åº”æ•°å€¼

è¿”å›JSONæ ¼å¼ï¼š
{
    "total_assets": æ•°å€¼æˆ–null,
    "total_liabilities": æ•°å€¼æˆ–null,
    "revenue": æ•°å€¼æˆ–null,
    "net_profit": æ•°å€¼æˆ–null
}"""
        
        # æ„å»ºç”¨æˆ·æç¤ºè¯
        user_prompt = f"""è¯·ä»ä»¥ä¸‹è´¢åŠ¡æŠ¥è¡¨æ–‡æœ¬ä¸­æå–æ•°æ®ï¼š

å…¬å¸ï¼š{company_name if company_name else 'æœªçŸ¥'}
å¹´ä»½ï¼š{year if year else 'æœªçŸ¥'}

æ–‡æœ¬å†…å®¹ï¼š
{text[:8000]}  # å¢åŠ æ–‡æœ¬é•¿åº¦ä»¥åŒ…å«æ›´å¤šè´¢åŠ¡æ•°æ®

è¯·ä»”ç»†æŸ¥æ‰¾å¹¶æå–ï¼š
1. TOTAL ASSETSï¼ˆæ€»èµ„äº§ï¼‰çš„æ•°å€¼
2. TOTAL LIABILITIESï¼ˆæ€»è´Ÿå€ºï¼‰çš„æ•°å€¼  
3. Revenue/Total Revenueï¼ˆè¥ä¸šæ”¶å…¥ï¼‰çš„æ•°å€¼
4. Net Profit/Net Lossï¼ˆå‡€åˆ©æ¶¦/å‡€äºæŸï¼‰çš„æ•°å€¼

å¦‚æœæ‰¾åˆ°å¤šä¸ªæœŸé—´çš„æ•°æ®ï¼Œè¯·æå–æœ€æ–°çš„æ•°æ®ã€‚"""
        
        # æ£€æŸ¥ç¼“å­˜
        cache_key = self._get_cache_key(text, user_prompt)
        cached_result = self._check_cache(cache_key)
        if cached_result:
            return cached_result
        
        # è°ƒç”¨API
        try:
            print(f"      ğŸŒ è°ƒç”¨DeepSeek API...")
            api_payload = {
                "model": "deepseek-chat",
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.1,
                "max_tokens": 500
            }
            
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=api_payload,
                timeout=30
            )
            
            print(f"      ğŸ“¡ APIå“åº”çŠ¶æ€: {response.status_code}")
            response.raise_for_status()
            result = response.json()
            
            # è§£æå“åº”
            content = result['choices'][0]['message']['content']
            
            # å°è¯•è§£æJSON
            try:
                import re
                json_match = re.search(r'\{[\s\S]*\}', content)
                if json_match:
                    extracted_data = json.loads(json_match.group())
                else:
                    extracted_data = self._parse_text_response(content)
            except:
                extracted_data = self._parse_text_response(content)
            
            # ä¿å­˜ç¼“å­˜
            self._save_cache(cache_key, extracted_data)
            
            return extracted_data
            
        except Exception as e:
            print(f"    âŒ APIè¯·æ±‚å¤±è´¥: {str(e)[:100]}")
            return {
                "total_assets": None,
                "total_liabilities": None,
                "revenue": None,
                "net_profit": None
            }
    
    def _parse_text_response(self, text: str) -> Dict:
        """è§£ææ–‡æœ¬æ ¼å¼çš„å“åº”"""
        import re
        
        result = {
            "total_assets": None,
            "total_liabilities": None,
            "revenue": None,
            "net_profit": None
        }
        
        # å®šä¹‰æ¨¡å¼
        patterns = {
            "total_assets": [
                r'æ€»èµ„äº§[:ï¼š]\s*([0-9,]+)',
                r'[Tt]otal\s+[Aa]ssets?[:ï¼š]\s*([0-9,]+)'
            ],
            "total_liabilities": [
                r'æ€»è´Ÿå€º[:ï¼š]\s*([0-9,]+)',
                r'[Tt]otal\s+[Ll]iabilities?[:ï¼š]\s*([0-9,]+)'
            ],
            "revenue": [
                r'è¥ä¸šæ”¶å…¥[:ï¼š]\s*([0-9,]+)',
                r'[Rr]evenue[:ï¼š]\s*([0-9,]+)'
            ],
            "net_profit": [
                r'å‡€åˆ©æ¶¦[:ï¼š]\s*\(?([0-9,]+)\)?',
                r'[Nn]et\s+[Pp]rofit[:ï¼š]\s*\(?([0-9,]+)\)?'
            ]
        }
        
        # å°è¯•åŒ¹é…
        for field, pattern_list in patterns.items():
            for pattern in pattern_list:
                match = re.search(pattern, text)
                if match:
                    try:
                        value = float(match.group(1).replace(',', ''))
                        result[field] = value
                        break
                    except:
                        pass
        
        return result


class LLMStrategy(BaseStrategy):
    """LLMæå–ç­–ç•¥"""
    
    def __init__(self, api_key: Optional[str] = None):
        """åˆå§‹åŒ–LLMç­–ç•¥"""
        super().__init__(name="llm")
        self.client = None
        
        try:
            self.client = DeepSeekClient(api_key)
            print("  âœ… LLMç­–ç•¥å·²åˆå§‹åŒ–")
        except Exception as e:
            print(f"  âš ï¸ LLMç­–ç•¥åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def can_handle(self, content: Any) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†"""
        return (
            self.client is not None and 
            isinstance(content, str) and 
            len(content) > 0
        )
    
    def extract(self, content: str, **kwargs) -> ExtractionResult:
        """ä½¿ç”¨LLMæå–è´¢åŠ¡æ•°æ®"""
        result = ExtractionResult(method="llm")
        
        if not self.client:
            print("    âŒ LLMå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return result
        
        try:
            # é™åˆ¶æ–‡æœ¬é•¿åº¦
            text_limit = kwargs.get('text_limit', 5000)
            limited_text = content[:text_limit] if content else ""
            
            if not limited_text:
                print("    âŒ æ²¡æœ‰æ–‡æœ¬å†…å®¹å¯ä¾›LLMæå–")
                return result
            
            print(f"    ğŸ“ å‡†å¤‡å‘é€ {len(limited_text)} å­—ç¬¦ç»™LLM...")
            
            # è°ƒç”¨LLMæå–
            llm_result = self.client.extract_financial_data(
                limited_text,
                company_name=kwargs.get('company_name', ''),
                year=kwargs.get('year', '')
            )
            
            if llm_result:
                print(f"    âœ… LLMè¿”å›ç»“æœ: {llm_result}")
                # è½¬æ¢ç»“æœ
                result.total_assets = llm_result.get('total_assets')
                result.total_liabilities = llm_result.get('total_liabilities')
                result.revenue = llm_result.get('revenue')
                result.net_profit = llm_result.get('net_profit')
                result.update_confidence()
                print(f"    ğŸ“Š æå–åˆ° {result.fields_count}/4 ä¸ªå­—æ®µ")
            else:
                print("    âš ï¸ LLMæœªè¿”å›æœ‰æ•ˆç»“æœ")
                
        except Exception as e:
            print(f"    âŒ LLMæå–å¼‚å¸¸: {str(e)}")
            import traceback
            traceback.print_exc()
        
        return result